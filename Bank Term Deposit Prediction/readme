Bank Term Deposit Prediction

Project Description
This project focuses on predicting whether a client will subscribe to a bank term deposit (yes or no) based on data from direct marketing campaigns of a Portuguese banking institution. The dataset includes customer attributes such as age, job type, marital status, education level, credit default status, average yearly balance, housing and personal loan status, contact method, and campaign details. The goal is to build machine learning models to accurately classify clients as likely or unlikely to subscribe, which is critical for optimizing marketing strategies in the banking industry.
The project is implemented in a Jupyter Notebook (Ensemble_Bank_dataset.ipynb), where I conducted exploratory data analysis (EDA), preprocessed the data, trained multiple machine learning models with a focus on ensemble methods, and evaluated their performance. The dataset posed challenges like imbalanced classes and missing or 'unknown' values, which I addressed to improve model outcomes. The analysis provides insights into customer behavior and model effectiveness, contributing to better decision-making for marketing campaigns.

My Work
I developed this project to apply machine learning techniques to a real-world banking problem. My work involved several key stages:
1.Exploratory Data Analysis (EDA): I thoroughly analyzed the dataset to understand its structure and identify patterns. I visualized distributions of features like age, balance, and campaign contacts using histograms and boxplots, and examined correlations to uncover relationships between variables. This revealed a significant class imbalance, with far more clients not subscribing ('no') than subscribing ('yes'), which influenced model performance.
2.Data Preprocessing: I prepared the data for modeling by addressing its challenges. For categorical features like job, marital status, and education, I applied label encoding to convert them into numerical values suitable for machine learning algorithms. I handled 'unknown' values in columns like job, education, contact, and poutcome, which were prevalent, by treating them as a separate category to retain information. Numerical features like age and balance were scaled using StandardScaler to ensure consistent ranges. I also explored outlier handling by replacing extreme values with mean or median but found it had minimal impact on results.
3.Model Training: I trained a variety of machine learning models to predict term deposit subscriptions. These included Logistic Regression, Naive Bayes, K-Nearest Neighbors (KNN), Support Vector Classifier (SVC), and Decision Trees. I placed special emphasis on ensemble methods, including Bagging, AdaBoost, Gradient Boosting, and Random Forest, due to their ability to improve predictive performance. For benchmarking purposes, I initially included the 'duration' feature (call duration), which significantly affects outcomes but is not available before a call. I later excluded it for realistic predictions, observing a slight accuracy drop.
4.Model Evaluation and Tuning: I evaluated models using metrics like accuracy, precision, recall, ROC-AUC, and confusion matrices. The confusion matrices highlighted that models excelled at predicting 'no' subscriptions (class 0) but struggled with 'yes' subscriptions (class 1) due to the dataset’s imbalance. To address this, I experimented with techniques like adjusting class weights, though the imbalance remained a challenge. I tuned ensemble models, particularly Decision Trees, by pruning to reduce complexity and improve interpretability. Gradient Boosting consistently outperformed other methods, achieving robust results.
5.Visualization and Insights: I created visualizations to communicate findings effectively. A line plot compared accuracy scores across models, showing SVC’s high performance (~90% with 'duration') and Gradient Boosting’s strength among ensembles. I visualized Decision Trees, noting that pruned trees were easier to interpret due to fewer leaf nodes. These visualizations helped highlight model strengths and dataset limitations.
6.Challenges and Solutions: The dataset’s imbalance was a major hurdle, as the large number of 'no' cases trained models to favor that class. I mitigated this by exploring class weighting and considering techniques like SMOTE (though not implemented to maintain computational efficiency). The presence of 'unknown' values required careful handling to avoid data loss. I also avoided using get_dummies for categorical encoding, as it increased dimensionality and computational cost without significant accuracy gains, prioritizing efficiency for potential large-scale applications.

Key Findings: My analysis showed that SVC performed best with the 'duration' feature due to its ability to create multiple hyperplanes, achieving ~90% accuracy. Without 'duration', accuracy dropped by ~0.5%, reflecting its influence. Gradient Boosting was the most effective ensemble method, balancing accuracy and robustness. Outlier handling had little impact, suggesting the dataset’s robustness to extreme values. The project underscored the need for balanced data to improve predictions for 'yes' subscriptions, suggesting future use of oversampling or synthetic data generation.

Through this project, I demonstrated skills in data analysis, preprocessing, model selection, and evaluation, tackling real-world challenges like imbalanced datasets and incomplete data. The work provides a foundation for further improvements, such as addressing class imbalance or integrating advanced feature engineering, to enhance predictive performance for banking applications.
